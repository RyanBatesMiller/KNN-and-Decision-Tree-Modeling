# KNN and Decision Tree Modeling

Use scikit-learn to train a DecisionTreeClassifier and KNeighborsClassifier on Adult Income data.

## Finding Best K Value

The best K-value to minimize cross-validated error on KNNeighborsClassifier: k = 15.
See Validation_Error_v._Number_of_Neighbors.png for plot data.

## Finding Best Depth Limit

The best depth limit to minimize DecisionTreeClassifier error: depth = 5.
See Error_vs._Depth_Limit.png for plot data.

## Performing Cross-Validation on Variable test/training sizes

See Cross_Validation_on_Decision_Tree_and_KNN.png.
